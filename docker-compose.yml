version: "2.3"

services:
  # 1. VAE Service (경로 수정됨)
  vae:
    build:
      context: .
      dockerfile: docker/Dockerfile.vae
    image: ood-vae:h100
    container_name: ood_vae_container
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - TZ=Asia/Seoul

    volumes:
      # [수정] 소스 코드: /workspace/src -> /app/src
      - ./src:/app/src

      # [수정] 데이터: /workspace/data -> /app/data
      - ./data:/app/data

      # [중요 변경] 모델 저장 경로 통일
      # 파이썬 코드가 /app/models/... 에 저장하므로, 호스트의 ./models 와 연결해야 함
      # (기존 ./checkpoints 대신 ./models 사용 권장)
      - ./models:/app/models

      # [중요 변경] 결과 저장 경로 통일
      # 호스트의 ./results 폴더에 통합 저장 (Animals-10/vae/...)
      - ./results:/app/results

    ports:
      - "8888:8888"
    shm_size: '32gb'

    # [참고] 컨테이너 시작 시 작업 디렉토리를 /app으로 설정하고 싶다면 working_dir 추가 가능
    working_dir: /app

    command: /bin/bash
    stdin_open: true
    tty: true
# 2. Classifier Service (최종 통합 환경)
  # -> 이 컨테이너에서 모든 학습/평가 코드를 실행합니다.
  classifier:
    build:
      context: .
      dockerfile: docker/Dockerfile.classifier
    image: animals-classifier:v1
    container_name: animals_classifier_container

    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - TZ=Asia/Seoul

    # [설정] Shared Memory (PyTorch DataLoader 속도 향상)
    shm_size: '16gb'

    # [포트] Jupyter, TensorBoard 연결
    ports:
      - "8889:8888" # Jupyter Lab
      - "6006:6006" # TensorBoard

    # [핵심] 볼륨 설정: 모든 경로를 /app 기준으로 통합
    volumes:
      # 1. 데이터: 호스트의 ./data -> 컨테이너의 /app/data
      - ./data:/app/data

      # 2. 모델: 호스트의 ./models -> 컨테이너의 /app/models (학습 모델 저장/로드)
      - ./models:/app/models

      # 3. 코드: 호스트의 ./src -> 컨테이너의 /app/src (모든 파이썬 코드)
      - ./src:/app/src

      # 4. 결과: 호스트의 ./results -> 컨테이너의 /app/results (CSV, 그래프, run_X 폴더 저장)
      - ./results:/app/results

    # 컨테이너가 종료되지 않고 계속 대기하도록 설정
    command: tail -f /dev/null